{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.11 64-bit ('tfxenv': conda)"
    },
    "interpreter": {
      "hash": "6d468f8d4b3a8fa99f0b8b2a7eeb41d1412ca7b959e796332de6fc9267d63a5a"
    },
    "colab": {
      "name": "tfx_workshop.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tEM8chrJ2133"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TFX Workshop\n",
        "\n",
        "TensorFlow Extended (TFX) is an end-to-end platform for deploying production ML pipelines.\n",
        "\n",
        "A TFX pipeline is a sequence of components that implement an ML pipeline which is specifically designed for scalable, high-performance machine learning tasks. Components are built using TFX libraries which can also be used individually.\n",
        "\n",
        "In this workshop we will understand \n",
        "\n",
        "1. Understanding TFX at high level.\n",
        "2. TFX Components\n",
        "3. TFX Pipeline\n",
        "\n",
        "We do this using an Image Classification dataset CIFAR 10.\n",
        "\n",
        "- TFX: https://www.tensorflow.org/tfx\n"
      ],
      "metadata": {
        "id": "7k-xU7-h213t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!git clone https://github.com/nvs-abhilash/tfx-workshop"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srckblXC3LHa",
        "outputId": "4a3d316a-0220-42cd-b7ac-61bb2d167f9d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# # Run this cell to setup TFX on Google Colab\r\n",
        "try:\r\n",
        "  import colab\r\n",
        "  !pip install --upgrade pip\r\n",
        "except:\r\n",
        "  pass\r\n",
        "!pip install -U tfx\r\n",
        "!pip install -U apache-beam[interactive]"
      ],
      "outputs": [],
      "metadata": {
        "id": "IUreuVhe213w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dd9660f9-1fba-48a6-a801-3d5153d29373"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://cloud.google.com/architecture/images/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning-3-ml-automation-ct.svg\"/>\n",
        "\n",
        "Source: https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning\n",
        "\n"
      ],
      "metadata": {
        "id": "gMbgfn6mUtgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: In Google Colab, because of package updates, the first time you run this cell you must restart the runtime (Runtime > Restart runtime ...).**"
      ],
      "metadata": {
        "id": "oAlXNDhW213x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.tensorflow.org/tfx/guide/images/prog_fin.png\" alt=\"TFX Component\"/>\n"
      ],
      "metadata": {
        "id": "hujoVx9q213y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.tensorflow.org/tfx/guide/images/libraries_components.png\" alt=\"TFX Libraries\"/>\n"
      ],
      "metadata": {
        "id": "fpR4edq4213y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFX Components: Interactive Orchestration\n",
        "\n",
        "### Background\n",
        "This notebook demonstrates how to use TFX in a Jupyter/Colab environment. Here, we walk through the CIFAR-10 example in an interactive notebook.\n",
        "\n",
        "Working in an interactive notebook is a useful way to become familiar with the structure of a TFX pipeline. It's also useful when doing development of your own pipelines as a lightweight development environment, but you should be aware that there are differences in the way interactive notebooks are orchestrated, and how they access metadata artifacts.\n",
        "\n",
        "### Orchestration\n",
        "In a production deployment of TFX, you will use an orchestrator such as Apache Airflow, Kubeflow Pipelines, or Apache Beam to orchestrate a pre-defined pipeline graph of TFX components. In an interactive notebook, the notebook itself is the orchestrator, running each TFX component as you execute the notebook cells.\n",
        "\n",
        "### Metadata\n",
        "In a production deployment of TFX, you will access metadata through the ML Metadata (MLMD) API. MLMD stores metadata properties in a database such as MySQL or SQLite, and stores the metadata payloads in a persistent store such as on your filesystem. In an interactive notebook, both properties and payloads are stored in an ephemeral SQLite database in the /tmp directory on the Jupyter notebook or Colab server.\n",
        "\n",
        "Adapted from: https://www.tensorflow.org/tfx/tutorials/tfx/components_keras"
      ],
      "metadata": {
        "id": "49qpcjtb213y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "from typing import List\r\n",
        "from tfx import v1 as tfx\r\n",
        "\r\n",
        "from tfx.components import ImportExampleGen\r\n",
        "from tfx.components import Pusher\r\n",
        "from tfx.components import SchemaGen\r\n",
        "from tfx.components import StatisticsGen\r\n",
        "from tfx.components import Trainer\r\n",
        "from tfx.components import Transform\r\n",
        "from tfx.orchestration import metadata\r\n",
        "from tfx.orchestration import pipeline\r\n",
        "from tfx.proto import example_gen_pb2\r\n",
        "from tfx.proto import pusher_pb2\r\n",
        "from tfx.proto import trainer_pb2\r\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext"
      ],
      "outputs": [],
      "metadata": {
        "id": "L3sMNJJW213z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check tensorflow and TFX versions"
      ],
      "metadata": {
        "id": "Te6opHGN2130"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print('TensorFlow version: {}'.format(tf.__version__))\r\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beqiOP6w2130",
        "outputId": "123f343e-b3ee-4514-a8cc-5a5b2a529d9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using a subset of CIFAR-10 dataset: https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "To use the entire dataset, run the following commands:\n",
        "```python\n",
        "import tensorflow_datasets as tfds \n",
        "ds = tfds.load('cifar10', data_dir='./cifar10/data/',split=['train', 'test'])\n",
        "```\n",
        "\n",
        "```bash\n",
        "mkdir -p tfx-workshop/cifar10_tfx/data/train_whole\n",
        "mkdir -p tfx-workshop/cifar10_tfx/data/test_whole\n",
        "mv cifar10/3.0.2/cifar10-train.tfrecord-00000-of-00001 tfx-workshop/cifar10_tfx/data/train_whole\n",
        "mv cifar10/3.0.2/cifar10-test.tfrecord-00000-of-00001 tfx-workshop/cifar10_tfx/data/test_whole\n",
        "rm -r cifar10\n",
        "```"
      ],
      "metadata": {
        "id": "LAbdXWSMj1T1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup the pipeline paths for artifacts, metadata, and output model generated to be used later"
      ],
      "metadata": {
        "id": "oKxnZUGw2131"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "_pipeline_name = \"cifar10-tfx\"\r\n",
        "\r\n",
        "_pipeline_root = os.path.join('pipelines', _pipeline_name)\r\n",
        "\r\n",
        "# Subset of CIFAR-10\r\n",
        "_data_root = \"tfx-workshop/cifar10_tfx/data\"\r\n",
        "\r\n",
        "# Trained model saved here\r\n",
        "_serving_model_dir = os.path.join('serving_model', _pipeline_name)\r\n",
        "\r\n",
        "# 10 classes of CIFAR\r\n",
        "_labels_path = os.path.join(_data_root, 'labels.txt')\r\n",
        "\r\n",
        "# Training module\r\n",
        "_trainer_module_file = \"tfx-workshop/cifar10_tfx/cifar10_trainer.py\"\r\n",
        "\r\n",
        "# Transform module\r\n",
        "_transform_module_file = \"tfx-workshop/cifar10_tfx/cifar10_transform.py\"\r\n",
        "\r\n",
        "# Will be used later for TFX pipeline\r\n",
        "_metadata_path = os.path.join('metadata', _pipeline_name, 'metadata.db')\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "GVgnyW-v2131"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an interactive context"
      ],
      "metadata": {
        "id": "tAY9Pe_h2131"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "context = InteractiveContext()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-xo6Yl62131",
        "outputId": "3ae0d5bb-d902-4720-bca6-75ac05daa205"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Components"
      ],
      "metadata": {
        "id": "io2QOPE02132"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ImportGen Component\n",
        "\n",
        "The ImportExampleGen component takes TFRecord files with TF Example data format, and generates train and eval examples for downstream components. This component provides consistent and configurable partition, and it also shuffle the dataset for ML best practice.\n",
        "\n",
        "More details: https://www.tensorflow.org/tfx/api_docs/python/tfx/v1/components/ImportExampleGen"
      ],
      "metadata": {
        "id": "gAPxdIsd2132"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "input_config = example_gen_pb2.Input(splits=[\r\n",
        "    example_gen_pb2.Input.Split(name='train', pattern='train/*'),\r\n",
        "    example_gen_pb2.Input.Split(name='eval', pattern='test/*')\r\n",
        "])\r\n",
        "example_gen = ImportExampleGen(input_base=_data_root,\r\n",
        "                               input_config=input_config)\r\n",
        "\r\n",
        "context.run(example_gen)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "EHY9vkwF2132",
        "outputId": "6c059578-34ca-4cbe-e2d4-f8dd56d7e077"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "artifact = example_gen.outputs['examples'].get()[0]\r\n",
        "print(artifact.split_names, artifact.uri)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4MLtYC_2132",
        "outputId": "6b444bbd-7962-4d27-c6ff-66d71ece870e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### StatisticsGen Component\n",
        "\n",
        "The StatisticsGen TFX pipeline component generates features statistics over both training and serving data, which can be used by other pipeline components. StatisticsGen uses Beam to scale to large datasets.\n",
        "\n",
        "Consumes: datasets created by an ExampleGen pipeline component.\n",
        "\n",
        "Emits: Dataset statistics.\n",
        "\n",
        "More details: https://www.tensorflow.org/tfx/guide/statsgen"
      ],
      "metadata": {
        "id": "WClH0IGM2132"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\r\n",
        "\r\n",
        "context.run(statistics_gen)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "6IbwghZs2132",
        "outputId": "ee4570bb-3f18-43b4-9120-2dadaa0ebe35"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "context.show(statistics_gen.outputs['statistics'])"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "by124atK2133",
        "outputId": "9ab31a90-7385-413d-a921-477be6bc8390"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SchemaGen Component\n",
        "\n"
      ],
      "metadata": {
        "id": "0gEaRkuL2133"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "schema_gen = SchemaGen(statistics=statistics_gen.outputs['statistics'],\r\n",
        "                           infer_feature_shape=True)\r\n",
        "\r\n",
        "context.run(schema_gen)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "XTA23Kvg2133",
        "outputId": "4380c50c-cd65-42f8-8baa-36d344477f1c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "context.show(schema_gen.outputs['schema'])"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "WkXCXV902133",
        "outputId": "bf17632f-c59b-41d0-9b57-110ecf82884a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform Component\n",
        "\n",
        "* Consumes: tf.Examples from an ExampleGen component, and a data schema from a SchemaGen component.\n",
        "* Emits: A SavedModel to a Trainer component, pre-transform and post-transform statistics.\n",
        "\n",
        "More details: https://www.tensorflow.org/tfx/guide/transform\n"
      ],
      "metadata": {
        "id": "tEM8chrJ2133"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "transform = Transform(examples=example_gen.outputs['examples'],\r\n",
        "                      schema=schema_gen.outputs['schema'],\r\n",
        "                      module_file=_transform_module_file)\r\n",
        "\r\n",
        "context.run(transform)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIJc-1ZP2134",
        "outputId": "6fa8b6c1-3942-42f8-eb53-aac606bbfd71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's examine the output artifacts of Transform. This component produces two types of outputs:\n",
        "\n",
        "* transform_graph is the graph that can perform the preprocessing operations (this graph will be included in the serving and evaluation models).\n",
        "* transformed_examples represents the preprocessed training and evaluation data."
      ],
      "metadata": {
        "id": "kJ2QZb762134"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_uri"
      ],
      "outputs": [],
      "metadata": {
        "id": "sLrP1_U_Ravj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_uri = transform.outputs['transform_graph'].get()[0].uri\r\n",
        "os.listdir(train_uri)"
      ],
      "outputs": [],
      "metadata": {
        "id": "qagG7_YE2134"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Get the URI of the output artifact representing the transformed examples, which is a directory\r\n",
        "# Get the URI of the output artifact representing the transformed examples, which is a directory\r\n",
        "train_uri = os.path.join(transform.outputs['transformed_examples'].get()[0].uri, 'Split-train')\r\n",
        "\r\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\r\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\r\n",
        "                      for name in os.listdir(train_uri)]\r\n",
        "\r\n",
        "# Create a `TFRecordDataset` to read these files\r\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\r\n",
        "\r\n",
        "# Doesn't work on Colab with default params\r\n",
        "# Iterate over the first record and decode them.\r\n",
        "for tfrecord in dataset.take(1):\r\n",
        "  serialized_example = tfrecord.numpy()\r\n",
        "  example = tf.train.Example()\r\n",
        "  example.ParseFromString(serialized_example)\r\n",
        "  print(example)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Bev7ywMN2134"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainer Component\n",
        "\n",
        "The Trainer TFX pipeline component trains a TensorFlow model.\n",
        "\n",
        "Trainer takes:\n",
        "* tf.Examples used for training and eval.\n",
        "* A user provided module file that defines the trainer logic.\n",
        "* Protobuf definition of train args and eval args.\n",
        "* (Optional) A data schema created by a SchemaGen pipeline component and optionally altered by the developer.\n",
        "* (Optional) transform graph produced by an upstream Transform component.\n",
        "* (Optional) pre-trained models used for scenarios such as warmstart.\n",
        "* (Optional) hyperparameters, which will be passed to user module function. Details of the integration with Tuner can be found here.\n",
        "\n",
        "Trainer emits: At least one model for inference/serving (typically in SavedModelFormat) and optionally another model for eval (typically an EvalSavedModel).\n",
        "\n",
        "More details: https://www.tensorflow.org/tfx/guide/trainer"
      ],
      "metadata": {
        "id": "d2mbg-KW2134"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "trainer = Trainer(module_file=_trainer_module_file,\r\n",
        "                  examples=transform.outputs['transformed_examples'],\r\n",
        "                  transform_graph=transform.outputs['transform_graph'],\r\n",
        "                  schema=schema_gen.outputs['schema'],\r\n",
        "                  train_args=trainer_pb2.TrainArgs(num_steps=16),\r\n",
        "                  eval_args=trainer_pb2.EvalArgs(num_steps=4),\r\n",
        "                  custom_config={'labels_path': _labels_path})\r\n",
        "context.run(trainer)"
      ],
      "outputs": [],
      "metadata": {
        "id": "jlwZP-eg2134"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_artifact_dir = trainer.outputs['model'].get()[0].uri\r\n",
        "print(os.listdir(model_artifact_dir))\r\n",
        "model_dir = os.path.join(model_artifact_dir, 'Format-Serving')\r\n",
        "print(os.listdir(model_dir))"
      ],
      "outputs": [],
      "metadata": {
        "id": "sHlIujMd2134"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_run_artifact_dir = trainer.outputs['model_run'].get()[0].uri\r\n",
        "\r\n",
        "%load_ext tensorboard\r\n",
        "%tensorboard --logdir {model_run_artifact_dir}"
      ],
      "outputs": [],
      "metadata": {
        "id": "AC43KFE72134"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pusher Component\n",
        "\n",
        "The Pusher component is used to push a validated model to a deployment target during model training or re-training. Before the deployment, Pusher relies on one or more blessings from other validation components to decide whether to push the model or not.\n",
        "\n",
        "A Pusher component consumes a trained model in SavedModel format, and produces the same SavedModel, along with versioning metadata.\n",
        "\n",
        "More details: https://www.tensorflow.org/tfx/guide/pusher"
      ],
      "metadata": {
        "id": "EE1Si86J2135"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pusher = Pusher(model=trainer.outputs['model'],\r\n",
        "                push_destination=pusher_pb2.PushDestination(\r\n",
        "                    filesystem=pusher_pb2.PushDestination.Filesystem(\r\n",
        "                        base_directory=_serving_model_dir)))\r\n",
        "context.run(pusher)"
      ],
      "outputs": [],
      "metadata": {
        "id": "oWJLNXy52135"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFX Pipeline\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/tfx/guide/images/tfx_pipeline_graph.svg\"/>\n",
        "\n",
        "Source: https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines\n",
        "\n",
        "\n",
        "Useful Guides: \n",
        "* https://www.tensorflow.org/tfx/guide/build_tfx_pipeline\n",
        "* https://www.tensorflow.org/tfx/guide/build_local_pipeline\n",
        "\n"
      ],
      "metadata": {
        "id": "imCWmlhR2135"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _create_pipeline(pipeline_name: str, \r\n",
        "                     pipeline_root: str, \r\n",
        "                     data_root: str,\r\n",
        "                     transform_module_file: str, \r\n",
        "                     trainer_module_file: str,\r\n",
        "                     serving_model_dir: str, \r\n",
        "                     metadata_path: str,\r\n",
        "                     labels_path: str) -> pipeline.Pipeline:\r\n",
        "    \"\"\"Implements the CIFAR10 image classification pipeline using TFX.\"\"\"\r\n",
        "    # This is needed for datasets with pre-defined splits\r\n",
        "    # Change the pattern argument to train_whole/* and test_whole/* to train\r\n",
        "    # on the whole CIFAR-10 dataset\r\n",
        "    input_config = example_gen_pb2.Input(splits=[\r\n",
        "        example_gen_pb2.Input.Split(name='train', pattern='train/*'),\r\n",
        "        example_gen_pb2.Input.Split(name='eval', pattern='test/*')\r\n",
        "    ])\r\n",
        "\r\n",
        "    # Brings data into the pipeline.\r\n",
        "    example_gen = ...\r\n",
        "\r\n",
        "    # Computes statistics over data for visualization and example validation.\r\n",
        "    statistics_gen = ...\r\n",
        "\r\n",
        "    # Generates schema based on statistics files.\r\n",
        "    schema_gen = ...\r\n",
        "\r\n",
        "    # Performs transformations and feature engineering in training and serving.\r\n",
        "    transform = ...\r\n",
        "\r\n",
        "    # Uses user-provided Python function that trains a model.\r\n",
        "    # When traning on the whole dataset, use 18744 for train steps, 156 for eval\r\n",
        "    # steps. 18744 train steps correspond to 24 epochs on the whole train set, and\r\n",
        "    # 156 eval steps correspond to 1 epoch on the whole test set. The\r\n",
        "    # configuration below is for training on the dataset we provided in the data\r\n",
        "    # folder, which has 128 train and 128 test samples. The 160 train steps\r\n",
        "    # correspond to 40 epochs on this tiny train set, and 4 eval steps correspond\r\n",
        "    # to 1 epoch on this tiny test set.\r\n",
        "    trainer = ...\r\n",
        "\r\n",
        "    # Checks whether the model passed the validation steps and pushes the model\r\n",
        "    # to a file destination if check passed.\r\n",
        "    pusher = ...\r\n",
        "\r\n",
        "    components = [...]\r\n",
        "\r\n",
        "    return pipeline.Pipeline(\r\n",
        "        pipeline_name=pipeline_name,\r\n",
        "        pipeline_root=pipeline_root,\r\n",
        "        components=components,\r\n",
        "        enable_cache=True,\r\n",
        "        metadata_connection_config=metadata.sqlite_metadata_connection_config(\r\n",
        "            metadata_path))\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "TMxvWHFj2135"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TFX Orchestration "
      ],
      "metadata": {
        "id": "zdV8-skF2135"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Local Dag Runner"
      ],
      "metadata": {
        "id": "0-QeqFio2136"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tfx.orchestration.LocalDagRunner().run(\r\n",
        "  _create_pipeline(\r\n",
        "      pipeline_name=_pipeline_name,\r\n",
        "      pipeline_root=_pipeline_root,\r\n",
        "      data_root=_data_root,\r\n",
        "      transform_module_file=_transform_module_file,\r\n",
        "      trainer_module_file=_trainer_module_file,\r\n",
        "      serving_model_dir=_serving_model_dir,\r\n",
        "      metadata_path=_metadata_path,\r\n",
        "      labels_path=_labels_path))"
      ],
      "outputs": [],
      "metadata": {
        "id": "O6Nt2jsK2136"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!cd serving_model && zip -r cifar10-tfx.zip cifar10-tfx"
      ],
      "outputs": [],
      "metadata": {
        "id": "TeOahyJDXZEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Airflow Dag Runner\n",
        "Airflow Orchestration Example: https://github.com/tensorflow/tfx/tree/master/tfx/examples/airflow_workshop"
      ],
      "metadata": {
        "id": "rr77Gqtca3WT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "* Simple TFX Pipeline Tutorial using Penguin dataset\n",
        ": https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple\n",
        "* CIFAR-10 Transfer Learning and MLKit integration Example: https://github.com/tensorflow/tfx/tree/master/tfx/examples/cifar10\n"
      ],
      "metadata": {
        "id": "z1srZUL62136"
      }
    }
  ]
}